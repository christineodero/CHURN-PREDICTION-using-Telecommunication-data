---
title: "CHURN PREDICTION using Telecommunication data"
author: "Christine_odero"
date: "`r Sys.Date()`"
output: html_document
---

CHURN PREDICTION using Telecommunication data

Customer churn, also known as customer attrition, is the loss of clients or customers. Churn is an important business metric for subscription-based services such as telecommunications companies. 
```{r}
# Clear up data in global environment
rm(list=ls())
```

```{r}
library(tidyverse)
library(readxl)
library(caret)
library(yardstick)
library(lime)
library(funModeling)
library(rsample)
library(recipes)
library(plyr)  
library(rpart.plot) 
library(caret)
library(gridExtra) 
library(tidyverse) 
library(rsample)
library(e1071) 
library(GGally)
library(data.table)
library(DT)
library(readr)
library(ggplot2)
library(tidyr)
library(corrplot)
library(rms)
library(MASS)
library(e1071)
library(ROCR)
library(gplots)
library(pROC)
library(rpart)
library(randomForest)
library(ggpubr)
```

```{r}
getwd()
setwd("/Users/christineodero/Documents/Telco_Churn")
```


```{r}
churn_data_raw <- read.csv('Telco-Customer-Churn.csv')

churn_data_raw %>% glimpse()
```

```{r}
df_status(churn_data_raw)
```
Data Preprocessing
```{r}
sapply(churn_data_raw, function(x) sum(is.na(x)))
```


```{r}
churn_data_raw[is.na(churn_data_raw$TotalCharges),]
```

```{r}
sum(is.na(churn_data_raw$TotalCharges))/nrow(churn_data_raw)
```
This subset is 0.16% of our data and is quite small. We will remove these cases in order to accomodate our further analyses.

```{r}
churn_data_clean<- churn_data_raw[complete.cases(churn_data_raw), ]
```

```{r}
churn_data_clean$SeniorCitizen <- as.factor(mapvalues(churn_data_clean$SeniorCitizen,
                                          from=c("0","1"),
                                          to=c("No", "Yes")))
```

```{r}
churn_data_clean$MultipleLines <- as.factor(mapvalues(churn_data_clean$MultipleLines, 
                                           from=c("No phone service"),
                                           to=c("No")))
```

```{r}
for(i in 10:15){
  churn_data_clean[,i] <- as.factor(mapvalues(churn_data_clean[,i],
                                  from= c("No internet service"), to= c("No")))
}
```

We will not need the customerID variable for graphs or modeling, so it can be removed.
```{r}
churn_data_clean$customerID <- NULL
```


Data Visualization For Descriptive Statistics
```{r}
#Gender plot
p1 <- ggplot(churn_data_clean, aes(x = gender)) +
  geom_bar(aes(fill = Churn)) +
  geom_text(aes(y = ..count.. -200, 
                label = paste0(round(prop.table(..count..),4) * 100, '%')), 
            stat = 'count', 
            position = position_dodge(.1), 
            size = 3)

#Senior citizen plot
p2 <- ggplot(churn_data_clean, aes(x = SeniorCitizen)) +
  geom_bar(aes(fill = Churn)) +
  geom_text(aes(y = ..count.. -200, 
                label = paste0(round(prop.table(..count..),4) * 100, '%')), 
            stat = 'count', 
            position = position_dodge(.1), 
            size = 3)

#Partner plot
p3 <- ggplot(churn_data_clean, aes(x = Partner)) +
  geom_bar(aes(fill = Churn)) +
  geom_text(aes(y = ..count.. -200, 
                label = paste0(round(prop.table(..count..),4) * 100, '%')), 
            stat = 'count', 
            position = position_dodge(.1), 
            size = 3)
#Dependents plot
p4 <- ggplot(churn_data_clean, aes(x = Dependents)) +
  geom_bar(aes(fill = Churn)) +
  geom_text(aes(y = ..count.. -200, 
                label = paste0(round(prop.table(..count..),4) * 100, '%')), 
            stat = 'count', 
            position = position_dodge(.1), 
            size = 3)

#Plot demographic data within a grid
grid.arrange(p1, p2, p3, p4, ncol=2)

```
From these demographic plots, we notice that the sample is evenly split across gender and partner status. A minority of the sample are senior citizens, and a minority have dependents.

```{r}
#Tenure histogram
p17 <- ggplot(data = churn_data_clean, aes(tenure, color = Churn))+
  geom_freqpoly(binwidth = 5, size = 1)

#Monthly charges histogram
p18 <- ggplot(data = churn_data_clean, aes(MonthlyCharges, color = Churn))+
  geom_freqpoly(binwidth = 5, size = 1)

#Total charges histogram
p19 <- ggplot(data = churn_data_clean, aes(TotalCharges, color = Churn))+
  geom_freqpoly(binwidth = 200, size = 1)

#Plot quantitative data within a grid
grid.arrange(p17, p18, p19, ncol=1)
```
The tenure variable is stacked at the tails, so a large proportin of customers have either been had the shortest (1 month) or longest (72 month) tenure. It appears as if the MonthlyCharges variable is roughly normaly distribued around $80 per month with a large stack near the lowest rates. The TotalCharges variable is positively skewed with a large stack near the lower amounts.

```{r}
p20 <- ggplot(churn_data_clean, aes(x = Churn)) +
  geom_bar(aes(fill = Churn)) +
  geom_text(aes(y = ..count.. -200, 
                label = paste0(round(prop.table(..count..),4) * 100, '%')), 
            stat = 'count', 
            position = position_dodge(.1), 
            size = 3)
p20
```
Roughly a quarter of our sample are no longer customers. 

Checking Correlation

```{r}
churn_data_clean %>%
  dplyr::select (TotalCharges, MonthlyCharges, tenure) %>%
  cor() %>%
  corrplot.mixed(upper = "circle", tl.col = "black", number.cex = 0.7)
```

The plot shows high correlations between Totalcharges & tenure and between TotalCharges & MonthlyCharges. Pay attention to these variables while training models later. Multicollinearity does not reduce the predictive power or reliability of the model as a whole, at least within the sample data set. But it affects calculations regarding individual predictors.

In order to assess the performance of our various modeling techniques, we can split the data into training and test subsets. We will model the training data and use these model parameters to make predictions with the test data. Let’s call these data subsets dtrain and dtest.

We will randomly sample from the entire sample to create these subsets. The ‘set.seed()’ function argument can be changed in order to reset the random number generator used for sampling. The training subset will be roughly 70% of the original sample, with the remaining being the test subset.

```{r}
set.seed(56)
split_train_test <- createDataPartition(churn_data_clean$Churn,p=0.7,list=FALSE)
dtrain<- churn_data_clean[split_train_test,]
dtest<-  churn_data_clean[-split_train_test,]

# Remove Total Charges from the training dataset

dtrain <- dtrain[,-19]
dtest <- dtest[,-19]
```
The tenure represents time period in months. To better find patterns with time, I change it to a factor with 5 levels, with each level represents a bin of tenure in years.

Modelling



DECISION TREE

```{r}
tr_fit <- rpart(Churn ~., data = dtrain, method="class")
rpart.plot(tr_fit)
```
From this decision tree, we can interpret the following:

The contract variable is the most important. Customers with month-to-month contracts are more likely to churn. Customers with DSL internet service are less likely to churn. Customers who have stayed longer than 15 months are less likely to churn. Now let’s assess the prediction accuracy of the decision tree model by investigating how well it predicts churn in the test subset. We will begin with the confustion matrix, which is a useful display of classification accuracy. It displays the following information:

true positives (TP): These are cases in which we predicted yes (they churned), and they did churn. true negatives (TN): We predicted no, and they didn’t churn. false positives (FP): We predicted yes, but they didn’t actually churn. (Also known as a “Type I error.”) false negatives (FN): We predicted no, but they actually churned. (Also known as a “Type II error.”) Let’s examine the confusion matrix for our decision tree model.

```{r}
tr_prob1 <- predict(tr_fit, dtest)
tr_pred1 <- ifelse(tr_prob1[,2] > 0.5,"Yes","No")
table(Predicted = tr_pred1, Actual = dtest$Churn)
```


The diagonal entries give our correct predictions, with the upper left being TN and the lower right being TP. The upper right gives the FN while the lower left gives the FP. From this confusion matrix, we can see that the model performs well at predicting non-churning customers but does not perform as well at predicting churning customers.

How about the overall accuracy of the decision tree model?

```{r}
tr_prob2 <- predict(tr_fit, dtrain)
tr_pred2 <- ifelse(tr_prob2[,2] > 0.5,"Yes","No")
tr_tab1 <- table(Predicted = tr_pred2, Actual = dtrain$Churn)
tr_tab2 <- table(Predicted = tr_pred1, Actual = dtest$Churn)
                 
```


```{r}
# Train
confusionMatrix(
  as.factor(tr_pred2),
  as.factor(dtrain$Churn),
  positive = "Yes"
)
```


```{r}
# Test
confusionMatrix(
as.factor(tr_pred1),
  as.factor(dtest$Churn),
  positive = "Yes" 
)
```



```{r}
tr_acc <- sum(diag(tr_tab2))/sum(tr_tab2)
tr_acc
```
The decision tree model is fairly accurate, correctly predicting the churn status of customers in the test subset 79% of the time.


RANDOM Forest Model

Random forest analysis is another machine learning classification method that is often used in customer churn analysis. The method operates by constructing multiple decision trees and constructing models based on summary statistics of these decision trees.

We will begin by identifying the number of variables randomly sampled as candidates at each split of the algorithm. In the randomForest package, this is referred to as the ‘mtry’ parameter or argument.

```{r}
#Set control parameters for random forest model selection
ctrl <- trainControl(method = "cv", number=5, 
                     classProbs = TRUE, summaryFunction = twoClassSummary)
```


```{r}
#Exploratory random forest model selection
rf_model <- train(Churn ~., data = dtrain,
                method = "rf",
                ntree = 75,
                tuneLength = 5,
                 metric = "ROC",
                 trControl = ctrl)

rf_model
```


```{r}
dtrain$Churn<-as.factor(dtrain$Churn)
```


```{r}
ctrl <- trainControl(method = "cv", number=5, 
                     classProbs = TRUE, summaryFunction = twoClassSummary)
#Run optimal model
rf_fit2 <- randomForest(Churn ~., data = dtrain, 
                        ntree = 75, mtry = 2,importance = TRUE, proximity = TRUE)
```


```{r}
#Display variable importance from random tree
varImpPlot(rf_fit2, sort=T, n.var = 10, 
           main = 'Top 10 important variables')

```
Similar to the decision tree, this random forest model has identified contract status and tenure length as important predictors for churn. Internet service status does not appear as important in this model, and the total charges variable is now highly emphasized.


```{r}
rf_pred1 <- predict(rf_fit2, dtest)
table(Predicted = rf_pred1, Actual = dtest$Churn)
```

```{r}
plot(rf_fit2)
```
The performance is somewhat similar to the decision tree model. The false negative rate is low  but the false positive rate is rather high. What about the overall accuracy?

```{r}
rf_pred2 <- predict(rf_fit2, dtrain)
rf_tab1 <- table(Predicted = rf_pred2, Actual = dtrain$Churn)
rf_tab2 <- table(Predicted = rf_pred1, Actual = dtest$Churn)
```

```{r}
# Train
confusionMatrix(
  as.factor(rf_pred2),
  as.factor(dtrain$Churn),
  positive = "Yes" 
)
```


```{r}
# Test
confusionMatrix(
as.factor(rf_pred1),
  as.factor(dtest$Churn),
  positive = "Yes" 
)
```

```{r}
rf_acc <- sum(diag(rf_tab2))/sum(rf_tab2)
rf_acc
```
Random forest model predict very good for the train data, but not very much on the test data. This indicating an onverfit on the model.

The random forest model is slightly more accurate than the decision tree model, being able to correctly predict the churn status of a customer in the test subset with 80% accuracy.

LOGISTIC REGRESSION
```{r}
lr_fit <- glm(Churn ~., data = dtrain,
          family=binomial(link='logit'))
summary(lr_fit)
```
Tenure length, contract status, and total charges have the lowest p-values and can be identified as the best predictors of customer churn.

```{r}
lr_prob1 <- predict(lr_fit, dtest, type="response")
lr_pred1 <- ifelse(lr_prob1 > 0.5,"Yes","No")
table(Predicted = lr_pred1, Actual = dtest$Churn)
```

```{r}
lr_prob2 <- predict(lr_fit, dtrain, type="response")
lr_pred2 <- ifelse(lr_prob2 > 0.5,"Yes","No")
lr_tab1 <- table(Predicted = lr_pred2, Actual = dtrain$Churn)
lr_tab2 <- table(Predicted = lr_pred1, Actual = dtest$Churn)
```

```{r}
# Train
confusionMatrix(
  as.factor(lr_pred2),
  as.factor(dtrain$Churn),
  positive = "Yes" 
)
```

```{r}
# Test
confusionMatrix(
as.factor(lr_pred1),
  as.factor(dtest$Churn),
  positive = "Yes" 
)
```


The 81.4% accuracy rate of the logistic regression model slightly outperforms the decision tree and random forest models.

SVM MODEL
```{r}
ctrl <- trainControl(method = "cv", number=5, 
                     classProbs = TRUE, summaryFunction = twoClassSummary)
```


```{r}
grid <- expand.grid(C = c(0.01, 0.05, 0.1, 0.25, 0.5, 1))

svm_linear_model <- train(Churn ~., data = dtrain, method = "svmLinear",
                 trControl= ctrl,
                 preProcess = c("center", "scale"),
                 tuneLength = 6,
                 tuneGrid = grid)

svm_linear_model
```

```{r}
plot(svm_linear_model, main = "Cross validation to determine cost parameter")
```

```{r}
svm_linear_pred <- predict(svm_linear_model, newdata = dtest)
```


```{r}
# Test
confusionMatrix(
as.factor(svm_linear_pred),
  as.factor(dtest$Churn),
  positive = "Yes" 
)
```
Summary
We identified several important churn predictor variables from the above models and compared their performance on accuracy performance. Based on the information and output above we find out that:  customers with month to month contract with paperless billing  and within 12 month tenure are more likely to churn, customers with internet services are more likely to churn.
In general tenure, contracts , monthly charges and internet services are the most important variables in Telco customer churn.
Logistic regression performed slightly better than SVM and All these other Models. 







